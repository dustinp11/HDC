{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dad5644-dc69-42ed-b390-adf53987293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchhd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec912a7a-f784-4c55-9db7-504a350d492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elementwise multiplication\n",
    "def binding(*hvs): \n",
    "    result = np.ones_like(hvs[0], dtype=complex)\n",
    "    for hv in hvs:\n",
    "        result *= hv\n",
    "    return result\n",
    "\n",
    "# elementwise sum\n",
    "def bundle(*hvs):\n",
    "    bundles = np.sum(hvs, axis=0)\n",
    "    return bundles \n",
    "\n",
    "# define similarity as the real part of the Hermitian inner product of hx and hy divided by the dim of hx\n",
    "def fhrr_similarity(hx, hy):\n",
    "    conjugate = np.conjugate(hy)\n",
    "    return np.real(np.dot(hx, conjugate)) / len(hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364072eb-dd15-4e6d-bc64-7ed1fd496a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 1, (5, 5))\n",
    "z = np.random.normal(0, 1, (5, 5))\n",
    "L = np.linalg.cholesky(np.eye(5))\n",
    "b = np.dot(a, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7409d8fa-708b-4e2c-abe5-b4a14b7cc00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_basis(D, n, distribution='gaussian', covariance=None):\n",
    "    \"\"\"\n",
    "    Generates encoding codebook for FHRR representations. Takes in n features outputs (n x D) encodebook in unexponentiated form.\n",
    "    Args:\n",
    "        D (int) - dimension of resulting vectors\n",
    "        n (int) - number of features \n",
    "        distribution (str) - the type of distribution (gaussian or uniform)\n",
    "        covariance (np.ndarray, optional) - n x n matrix for gaussian distribution)\n",
    "    Returns:\n",
    "        np.ndarray - encoding basis in unexponentiated form W (n x D)e\n",
    "    \"\"\"\n",
    "    if distribution == 'gaussian':\n",
    "        if covariance is None:\n",
    "            covariance = np.eye(n)\n",
    "        basis = np.random.multivariate_normal(np.zeros(n), covariance, D).T\n",
    "    else: # uniform\n",
    "        basis = np.random.uniform(0, 2 * np.pi, (n, D))\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6822bf-8384-4024-a09d-128082580b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gen_basis(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12807d43-497e-409b-88dc-20974ef5e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature(C, features):\n",
    "    \"\"\"\n",
    "    Encodes feature vectors using FHRR with optional fractional power encoding. \n",
    "    Args:\n",
    "        C (np.ndarray) - the codebook encoded in unexponentiated form W (n x D)\n",
    "        features (np.ndarray) - feature vectors to encode, every feature is a row (batch size x n) \n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray - encoded features in FHRR form (batch size x D) , complex values\n",
    "    \"\"\"\n",
    "    phase = np.dot(features, C)\n",
    "    return np.exp(1j * phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e349f533-7d8a-47c9-915b-a3ab70947e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_1d_gaussian(D=500, variance=1.0, feature_range=(-4, 4), num_points=100):\n",
    "    \"\"\"Visualize kernel behavior for 1D feature space with Gaussian distribution\"\"\"\n",
    "    # Generate basis\n",
    "    codebook = gen_basis(D, 1, distribution=\"gaussian\", covariance=np.array([[variance]]))\n",
    "    \n",
    "    # Create reference point at 0\n",
    "    # reference = np.array([0.0])\n",
    "    # encoded_reference = encode_feature(codebook, reference)\n",
    "    \n",
    "    # # Generate test points across the feature range\n",
    "    # feature_diffs = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    # test_features = feature_diffs.reshape(-1, 1)\n",
    "    # encoded_tests = encode_feature(codebook, test_features)\n",
    "    \n",
    "    # # Compute similarities\n",
    "    # similarities = np.array([fhrr_similarity(encoded_reference, encoded_test) \n",
    "    #                         for encoded_test in encoded_tests])\n",
    "    \n",
    "    # # Plot\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.plot(feature_diffs, similarities)\n",
    "    # plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    # plt.axvline(x=0, color='r', linestyle='-', alpha=0.3)\n",
    "    # plt.grid(True, alpha=0.3)\n",
    "    # plt.title(f'1D Gaussian Kernel (σ² = {variance})')\n",
    "    # plt.xlabel('Feature Difference')\n",
    "    # plt.ylabel('Similarity')\n",
    "    # plt.ylim(-0.2, 1.05)\n",
    "    # plt.savefig('1d_gaussian_kernel.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # return similarities, feature_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe0e09-8011-4018-a594-be6e11faf580",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_1d_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafdae92-6f68-4ad3-ac05-a5d5f7021b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_2d_diagonal_gaussian(D=1000, variance=1.0, feature_range=(-4, 4), num_points=50):\n",
    "    \"\"\"Visualize kernel behavior for 2D feature space with diagonal Gaussian covariance\"\"\"\n",
    "    # Generate basis with diagonal covariance\n",
    "    cov_matrix = np.array([[variance, 0], [0, variance]])\n",
    "    codebook = gen_basis(D, 2, distribution=\"gaussian\", covariance=cov_matrix)\n",
    "    \n",
    "    # Create reference point at origin\n",
    "    reference = np.array([0.0, 0.0])\n",
    "    encoded_reference = encode_feature(codebook, reference)\n",
    "    \n",
    "    # Generate grid of test points\n",
    "    x = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    y = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    test_features = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    encoded_tests = encode_feature(codebook, test_features)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = np.array([fhrr_similarity(encoded_reference, encoded_test) \n",
    "                            for encoded_test in encoded_tests])\n",
    "    similarities_grid = similarities.reshape(num_points, num_points)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(similarities_grid, extent=[feature_range[0], feature_range[1], \n",
    "                                         feature_range[0], feature_range[1]], \n",
    "               origin='lower', cmap='viridis', interpolation='bilinear')\n",
    "    plt.colorbar(label='Similarity')\n",
    "    plt.grid(False)\n",
    "    plt.title(f'2D Gaussian Kernel with Diagonal Covariance (σ² = {variance})')\n",
    "    plt.xlabel('Feature Difference (x)')\n",
    "    plt.ylabel('Feature Difference (y)')\n",
    "    plt.savefig('2d_diagonal_gaussian_kernel.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also create a contour plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    contour = plt.contourf(X, Y, similarities_grid, levels=20, cmap='viridis')\n",
    "    plt.colorbar(contour, label='Similarity')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title(f'2D Gaussian Kernel Contour (σ² = {variance})')\n",
    "    plt.xlabel('Feature Difference (x)')\n",
    "    plt.ylabel('Feature Difference (y)')\n",
    "    plt.savefig('2d_diagonal_gaussian_contour.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return similarities_grid, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad5162-f490-4bbc-b767-807a5c28a840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d569ee3-bd31-4c21-b773-82cd540bc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bound_1d_gaussian(D=1000, variance=1.0, feature_range=(-4, 4), num_points=100):\n",
    "    \"\"\"Visualize kernel behavior for two 1D features bound together\"\"\"\n",
    "    # Generate two independent bases\n",
    "    codebook1 = gen_basis(D, 1, distribution=\"gaussian\", covariance=np.array([[variance]]))\n",
    "    codebook2 = gen_basis(D, 1, distribution=\"gaussian\", covariance=np.array([[variance]]))\n",
    "    \n",
    "    # Create reference points at 0\n",
    "    reference = np.array([0.0])\n",
    "    encoded_reference1 = encode_feature(codebook1, reference)\n",
    "    encoded_reference2 = encode_feature(codebook2, reference)\n",
    "    bound_reference = binding(encoded_reference1, encoded_reference2)\n",
    "    \n",
    "    # Generate test points\n",
    "    feature_diffs = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    \n",
    "    # Method 1: Vary both features equally\n",
    "    similarities_m1 = []\n",
    "    for diff in feature_diffs:\n",
    "        test_feature = np.array([diff])\n",
    "        encoded_test1 = encode_feature(codebook1, test_feature)\n",
    "        encoded_test2 = encode_feature(codebook2, test_feature)\n",
    "        bound_test = binding(encoded_test1, encoded_test2)\n",
    "        similarities_m1.append(fhrr_similarity(bound_reference, bound_test))\n",
    "    \n",
    "    # Method 2: Create 2D grid and use diagonal\n",
    "    x = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    y = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    diagonal_idx = np.diag_indices(num_points)\n",
    "    test_features_x = X[diagonal_idx].reshape(-1, 1)\n",
    "    test_features_y = Y[diagonal_idx].reshape(-1, 1)\n",
    "    \n",
    "    encoded_tests_x = encode_feature(codebook1, test_features_x)\n",
    "    encoded_tests_y = encode_feature(codebook2, test_features_y)\n",
    "    \n",
    "    bound_tests = binding(encoded_tests_x, encoded_tests_y)\n",
    "    similarities_m2 = np.array([fhrr_similarity(bound_reference, bound_test) \n",
    "                              for bound_test in bound_tests])\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(feature_diffs, similarities_m1, label='Method 1: Same difference for both features')\n",
    "    plt.plot(feature_diffs, similarities_m2, '--', label='Method 2: Diagonal of 2D grid')\n",
    "    plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.title(f'Bound 1D Gaussian Kernels (σ² = {variance})')\n",
    "    plt.xlabel('Feature Difference')\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.ylim(-0.2, 1.05)\n",
    "    plt.savefig('bound_1d_gaussian_kernel.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return similarities_m1, similarities_m2, feature_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74599cff-23dc-48cc-8ad6-2da118b35ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_2d_nondiagonal_gaussian(D=1000, feature_range=(-4, 4), num_points=50):\n",
    "    \"\"\"Visualize kernel behavior for 2D feature space with non-diagonal Gaussian covariance\"\"\"\n",
    "    # Generate basis with non-diagonal covariance\n",
    "    # Using a correlation of 0.7 for demonstration\n",
    "    variance = 1.0\n",
    "    correlation = 0.7\n",
    "    cov_matrix = np.array([[variance, correlation * variance], \n",
    "                           [correlation * variance, variance]])\n",
    "    \n",
    "    codebook = gen_basis(D, 2, distribution=\"gaussian\", covariance=cov_matrix)\n",
    "    \n",
    "    # Create reference point at origin\n",
    "    reference = np.array([0.0, 0.0])\n",
    "    encoded_reference = encode_feature(codebook, reference)\n",
    "    \n",
    "    # Generate grid of test points\n",
    "    x = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    y = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    test_features = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    encoded_tests = encode_feature(codebook, test_features)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = np.array([fhrr_similarity(encoded_reference, encoded_test) \n",
    "                            for encoded_test in encoded_tests])\n",
    "    similarities_grid = similarities.reshape(num_points, num_points)\n",
    "    \n",
    "    # Plot contour\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    contour = plt.contourf(X, Y, similarities_grid, levels=20, cmap='viridis')\n",
    "    plt.colorbar(contour, label='Similarity')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title(f'2D Gaussian Kernel with Non-Diagonal Covariance (Correlation = {correlation})')\n",
    "    plt.xlabel('Feature Difference (x)')\n",
    "    plt.ylabel('Feature Difference (y)')\n",
    "    plt.savefig('2d_nondiagonal_gaussian_contour.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return similarities_grid, X, Y, cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8048ab9-cf0c-4ba6-a698-30b35044e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_1d_uniform(D=1000, feature_range=(-4*np.pi, 4*np.pi), num_points=200):\n",
    "    \"\"\"Visualize kernel behavior for 1D feature space with uniform distribution\"\"\"\n",
    "    # Generate basis with uniform distribution\n",
    "    codebook = gen_basis(D, 1, distribution=\"uniform\")\n",
    "    \n",
    "    # Create reference point at 0\n",
    "    reference = np.array([0.0])\n",
    "    encoded_reference = encode_feature(codebook, reference)\n",
    "    \n",
    "    # Generate test points across the feature range\n",
    "    feature_diffs = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    test_features = feature_diffs.reshape(-1, 1)\n",
    "    encoded_tests = encode_feature(codebook, test_features)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = np.array([fhrr_similarity(encoded_reference, encoded_test) \n",
    "                            for encoded_test in encoded_tests])\n",
    "    \n",
    "    # Theoretical sinc function for comparison\n",
    "    def sinc(x):\n",
    "        return np.sinc(x / np.pi)  # numpy's sinc is sin(πx)/(πx)\n",
    "    \n",
    "    theoretical = sinc(feature_diffs)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(feature_diffs, similarities, label='FHRR Similarity')\n",
    "    plt.plot(feature_diffs, theoretical, '--', label='Theoretical sinc')\n",
    "    plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.title('1D Uniform Distribution Kernel')\n",
    "    plt.xlabel('Feature Difference')\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.ylim(-0.4, 1.05)\n",
    "    plt.savefig('1d_uniform_kernel.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return similarities, feature_diffs, theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e399481-391c-4db8-b741-4b7838c2f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_2d_uniform(D=1000, feature_range=(-4*np.pi, 4*np.pi), num_points=100):\n",
    "    \"\"\"Visualize kernel behavior for 2D feature space with uniform distribution\"\"\"\n",
    "    # Generate basis with uniform distribution\n",
    "    codebook = gen_basis(D, 2, distribution=\"uniform\")\n",
    "    \n",
    "    # Create reference point at origin\n",
    "    reference = np.array([0.0, 0.0])\n",
    "    encoded_reference = encode_feature(codebook, reference)\n",
    "    \n",
    "    # Generate grid of test points\n",
    "    x = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    y = np.linspace(feature_range[0], feature_range[1], num_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    test_features = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    encoded_tests = encode_feature(codebook, test_features)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = np.array([fhrr_similarity(encoded_reference, encoded_test) \n",
    "                            for encoded_test in encoded_tests])\n",
    "    similarities_grid = similarities.reshape(num_points, num_points)\n",
    "    \n",
    "    # Plot contour\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    contour = plt.contourf(X, Y, similarities_grid, levels=20, cmap='viridis')\n",
    "    plt.colorbar(contour, label='Similarity')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title('2D Uniform Distribution Kernel')\n",
    "    plt.xlabel('Feature Difference (x)')\n",
    "    plt.ylabel('Feature Difference (y)')\n",
    "    plt.savefig('2d_uniform_contour.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return similarities_grid, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76decc7b-f3cf-45a7-a748-d870ff06b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments(D=2000, save=True):\n",
    "    \"\"\"Run all kernel experiments with specified hyperdimension\"\"\"\n",
    "    print(f\"Running all experiments with hyperdimension D={D}\")\n",
    "    \n",
    "    # A. 1D Gaussian\n",
    "    print(\"Experiment A: 1D Gaussian\")\n",
    "    variance_a = 1.0\n",
    "    similarities_a, feature_diffs_a = visualize_1d_gaussian(\n",
    "        D=D, variance=variance_a, feature_range=(-6, 6), num_points=200)\n",
    "    \n",
    "    # B. 2D Gaussian with diagonal covariance\n",
    "    print(\"Experiment B: 2D Diagonal Gaussian\")\n",
    "    variance_b = 1.0\n",
    "    similarities_b, X_b, Y_b = visualize_2d_diagonal_gaussian(\n",
    "        D=D, variance=variance_b, feature_range=(-4, 4), num_points=50)\n",
    "    \n",
    "    # C. Two 1D Gaussian spaces with binding\n",
    "    print(\"Experiment C: Bound 1D Gaussian\")\n",
    "    variance_c = 1.0\n",
    "    similarities_c1, similarities_c2, feature_diffs_c = visualize_bound_1d_gaussian(\n",
    "        D=D, variance=variance_c, feature_range=(-6, 6), num_points=200)\n",
    "    \n",
    "    # D. 2D Gaussian with non-diagonal covariance\n",
    "    print(\"Experiment D: 2D Non-Diagonal Gaussian\")\n",
    "    similarities_d, X_d, Y_d, cov_matrix_d = visualize_2d_nondiagonal_gaussian(\n",
    "        D=D, feature_range=(-4, 4), num_points=50)\n",
    "    \n",
    "    # E. 1D Uniform distribution\n",
    "    print(\"Experiment E: 1D Uniform\")\n",
    "    similarities_e, feature_diffs_e, theoretical_e = visualize_1d_uniform(\n",
    "        D=D, feature_range=(-6*np.pi, 6*np.pi), num_points=400)\n",
    "    \n",
    "    # F. 2D Uniform distribution\n",
    "    print(\"Experiment F: 2D Uniform\")\n",
    "    similarities_f, X_f, Y_f = visualize_2d_uniform(\n",
    "        D=D, feature_range=(-4*np.pi, 4*np.pi), num_points=100)\n",
    "    \n",
    "    print(\"All experiments completed!\")\n",
    "    \n",
    "    return {\n",
    "        \"exp_a\": (similarities_a, feature_diffs_a, variance_a),\n",
    "        \"exp_b\": (similarities_b, X_b, Y_b, variance_b),\n",
    "        \"exp_c\": (similarities_c1, similarities_c2, feature_diffs_c, variance_c),\n",
    "        \"exp_d\": (similarities_d, X_d, Y_d, cov_matrix_d),\n",
    "        \"exp_e\": (similarities_e, feature_diffs_e, theoretical_e),\n",
    "        \"exp_f\": (similarities_f, X_f, Y_f)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa7488-4f27-439d-a38f-0b76d8e20a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
